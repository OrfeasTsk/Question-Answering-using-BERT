{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "AI2_HW4_SQUAD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Library Imports**"
      ],
      "metadata": {
        "id": "oFdHJ1i2yZuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import string\n",
        "import re\n",
        "\n",
        "from collections import namedtuple, Counter\n",
        "import json\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from itertools import cycle\n",
        "\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from os import path\n",
        "import sys\n",
        "\n",
        "if 'transformers' not in sys.modules:\n",
        "  !{sys.executable} -m pip install transformers\n",
        "\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering, BatchEncoding, get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "08pfm72ayRh-",
        "outputId": "16db3058-7af6-4e8d-8ca4-ddf709acaafb",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:34.112378Z",
          "iopub.execute_input": "2022-03-02T16:17:34.112693Z",
          "iopub.status.idle": "2022-03-02T16:17:52.794740Z",
          "shell.execute_reply.started": "2022-03-02T16:17:34.112607Z",
          "shell.execute_reply": "2022-03-02T16:17:52.793690Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.2.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.10.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SQuAD 2.0 download and preprocessing**"
      ],
      "metadata": {
        "id": "wbZ-VjoczjnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O dev-v2.0.json"
      ],
      "metadata": {
        "id": "VVTNXiZ7zeZN",
        "outputId": "e107328f-0c26-4884-b9e4-e8a2e0906b8a",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:52.797310Z",
          "iopub.execute_input": "2022-03-02T16:17:52.797738Z",
          "iopub.status.idle": "2022-03-02T16:17:56.842488Z",
          "shell.execute_reply.started": "2022-03-02T16:17:52.797661Z",
          "shell.execute_reply": "2022-03-02T16:17:56.841386Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2022-03-02 16:17:53--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\nResolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.109.153, 185.199.111.153, ...\nConnecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 42123633 (40M) [application/json]\nSaving to: ‘train-v2.0.json’\n\ntrain-v2.0.json     100%[===================>]  40.17M   204MB/s    in 0.2s    \n\n2022-03-02 16:17:55 (204 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n\n--2022-03-02 16:17:55--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\nResolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.110.153, ...\nConnecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4370528 (4.2M) [application/json]\nSaving to: ‘dev-v2.0.json’\n\ndev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.04s   \n\n2022-03-02 16:17:56 (111 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation for both **train** and **dev** sets of SQuAD 2.0  by parsing their **JSON** representations. Each dataset contains the **context text**, the **question text**, the **answer start and end indices of the characters** in the context (they are fixed in case of misalignment) and the **text for every valid answer** (the main answer is considered to be the first one and is seperated from the other answers)"
      ],
      "metadata": {
        "id": "neZKj9481PEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start and end positions for some answers are not aligned to the real context by one or two characters\n",
        "def fixAnswerAlignment(context, answer, answer_start_idx, answer_end_idx):\n",
        "  for i in range(3):\n",
        "    if context[(answer_start_idx - i):(answer_end_idx + 1 - i)] == answer:\n",
        "      return answer_start_idx - i, answer_end_idx - i\n",
        "\n",
        "def parseSquad(squad_file):\n",
        "  with open(squad_file, 'rb') as f:\n",
        "    squad_json = json.load(f)\n",
        "\n",
        "  mode = squad_file.split('-')[0]\n",
        "  squad_list = []\n",
        "\n",
        "  for section in squad_json['data']:\n",
        "    for paragraph in section['paragraphs']:\n",
        "      context = paragraph['context'].strip()\n",
        "      for qa in paragraph['qas']:\n",
        "          question = qa['question'].strip()\n",
        "          answers = qa['answers'] if not qa['is_impossible'] else None\n",
        "          if answers is not None and len(answers) > 0:\n",
        "            # Always the first answer is selected as the main answer\n",
        "            answer = answers[0]['text'].strip()\n",
        "            answer_start_idx = answers[0]['answer_start']\n",
        "            answer_end_idx = answer_start_idx + len(answer) - 1\n",
        "            answer_start_idx, answer_end_idx = fixAnswerAlignment(context, answer, answer_start_idx, answer_end_idx)\n",
        "            # The other answers are also included only for the evaluation/dev dataset\n",
        "            other_answers = [answers[i]['text'].strip() for i in range(1, len(answers))] if mode == 'dev' else None\n",
        "            squad_list.append({'context': context, 'question': question, 'answer': answer, 'answer_start_idx': answer_start_idx, 'answer_end_idx': answer_end_idx, 'other_answers': other_answers})\n",
        "          else:\n",
        "            squad_list.append({'context': context, 'question': question, 'answer': None, 'answer_start_idx': -1, 'answer_end_idx': -1, 'other_answers': None})\n",
        "\n",
        "  return pd.DataFrame(squad_list, columns = ['context', 'question', 'answer', 'answer_start_idx', 'answer_end_idx', 'other_answers']).dropna(axis = 1, how = 'all') \n"
      ],
      "metadata": {
        "id": "0r7oCQSr1OU0",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:56.845031Z",
          "iopub.execute_input": "2022-03-02T16:17:56.845345Z",
          "iopub.status.idle": "2022-03-02T16:17:56.863895Z",
          "shell.execute_reply.started": "2022-03-02T16:17:56.845303Z",
          "shell.execute_reply": "2022-03-02T16:17:56.862605Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = parseSquad('train-v2.0.json') #.sample(frac = 0.8, random_state = 1).sort_index()\n",
        "validation_set = parseSquad('dev-v2.0.json')\n",
        "\n",
        "display(training_set.head(10))\n",
        "print(f'Training set size: {len(training_set)}')\n",
        "display(validation_set.head(10))\n",
        "print(f'Validation set size: {len(validation_set)}')"
      ],
      "metadata": {
        "id": "21O2CLe7NGXE",
        "outputId": "811642dd-b032-4118-e689-cafd9738bbb2",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:56.867702Z",
          "iopub.execute_input": "2022-03-02T16:17:56.868390Z",
          "iopub.status.idle": "2022-03-02T16:17:59.202978Z",
          "shell.execute_reply.started": "2022-03-02T16:17:56.868343Z",
          "shell.execute_reply": "2022-03-02T16:17:59.201626Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                             context  \\\n0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n5  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n6  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n7  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n8  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n9  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n\n                                            question               answer  \\\n0           When did Beyonce start becoming popular?    in the late 1990s   \n1  What areas did Beyonce compete in when she was...  singing and dancing   \n2  When did Beyonce leave Destiny's Child and bec...                 2003   \n3       In what city and state did Beyonce  grow up?       Houston, Texas   \n4         In which decade did Beyonce become famous?           late 1990s   \n5         In what R&B group was she the lead singer?      Destiny's Child   \n6      What album made her a worldwide known artist?  Dangerously in Love   \n7             Who managed the Destiny's Child group?       Mathew Knowles   \n8                     When did Beyoncé rise to fame?           late 1990s   \n9     What role did Beyoncé have in Destiny's Child?          lead singer   \n\n   answer_start_idx  answer_end_idx  \n0               269             285  \n1               207             225  \n2               526             529  \n3               166             179  \n4               276             285  \n5               320             334  \n6               505             523  \n7               360             373  \n8               276             285  \n9               290             300  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>answer_start_idx</th>\n      <th>answer_end_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>When did Beyonce start becoming popular?</td>\n      <td>in the late 1990s</td>\n      <td>269</td>\n      <td>285</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>What areas did Beyonce compete in when she was...</td>\n      <td>singing and dancing</td>\n      <td>207</td>\n      <td>225</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>When did Beyonce leave Destiny's Child and bec...</td>\n      <td>2003</td>\n      <td>526</td>\n      <td>529</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>In what city and state did Beyonce  grow up?</td>\n      <td>Houston, Texas</td>\n      <td>166</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>In which decade did Beyonce become famous?</td>\n      <td>late 1990s</td>\n      <td>276</td>\n      <td>285</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>In what R&amp;B group was she the lead singer?</td>\n      <td>Destiny's Child</td>\n      <td>320</td>\n      <td>334</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>What album made her a worldwide known artist?</td>\n      <td>Dangerously in Love</td>\n      <td>505</td>\n      <td>523</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>Who managed the Destiny's Child group?</td>\n      <td>Mathew Knowles</td>\n      <td>360</td>\n      <td>373</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>When did Beyoncé rise to fame?</td>\n      <td>late 1990s</td>\n      <td>276</td>\n      <td>285</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>What role did Beyoncé have in Destiny's Child?</td>\n      <td>lead singer</td>\n      <td>290</td>\n      <td>300</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Training set size: 130319\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                             context  \\\n0  The Normans (Norman: Nourmands; French: Norman...   \n1  The Normans (Norman: Nourmands; French: Norman...   \n2  The Normans (Norman: Nourmands; French: Norman...   \n3  The Normans (Norman: Nourmands; French: Norman...   \n4  The Normans (Norman: Nourmands; French: Norman...   \n5  The Normans (Norman: Nourmands; French: Norman...   \n6  The Normans (Norman: Nourmands; French: Norman...   \n7  The Normans (Norman: Nourmands; French: Norman...   \n8  The Normans (Norman: Nourmands; French: Norman...   \n9  The Norman dynasty had a major political, cult...   \n\n                                            question  \\\n0               In what country is Normandy located?   \n1                 When were the Normans in Normandy?   \n2      From which countries did the Norse originate?   \n3                          Who was the Norse leader?   \n4  What century did the Normans first gain their ...   \n5  Who gave their name to Normandy in the 1000's ...   \n6                        What is France a region of?   \n7          Who did King Charles III swear fealty to?   \n8             When did the Frankish identity emerge?   \n9        Who was the duke in the battle of Hastings?   \n\n                        answer  answer_start_idx  answer_end_idx  \\\n0                       France               159             164   \n1      10th and 11th centuries                94             116   \n2  Denmark, Iceland and Norway               256             282   \n3                        Rollo               308             312   \n4                 10th century               671             682   \n5                         None                -1              -1   \n6                         None                -1              -1   \n7                         None                -1              -1   \n8                         None                -1              -1   \n9        William the Conqueror              1022            1042   \n\n                                       other_answers  \n0                           [France, France, France]  \n1  [in the 10th and 11th centuries, 10th and 11th...  \n2  [Denmark, Iceland and Norway, Denmark, Iceland...  \n3                              [Rollo, Rollo, Rollo]  \n4   [the first half of the 10th century, 10th, 10th]  \n5                                               None  \n6                                               None  \n7                                               None  \n8                                               None  \n9     [William the Conqueror, William the Conqueror]  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>answer_start_idx</th>\n      <th>answer_end_idx</th>\n      <th>other_answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>In what country is Normandy located?</td>\n      <td>France</td>\n      <td>159</td>\n      <td>164</td>\n      <td>[France, France, France]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>When were the Normans in Normandy?</td>\n      <td>10th and 11th centuries</td>\n      <td>94</td>\n      <td>116</td>\n      <td>[in the 10th and 11th centuries, 10th and 11th...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>From which countries did the Norse originate?</td>\n      <td>Denmark, Iceland and Norway</td>\n      <td>256</td>\n      <td>282</td>\n      <td>[Denmark, Iceland and Norway, Denmark, Iceland...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>Who was the Norse leader?</td>\n      <td>Rollo</td>\n      <td>308</td>\n      <td>312</td>\n      <td>[Rollo, Rollo, Rollo]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>What century did the Normans first gain their ...</td>\n      <td>10th century</td>\n      <td>671</td>\n      <td>682</td>\n      <td>[the first half of the 10th century, 10th, 10th]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>Who gave their name to Normandy in the 1000's ...</td>\n      <td>None</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>What is France a region of?</td>\n      <td>None</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>Who did King Charles III swear fealty to?</td>\n      <td>None</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n      <td>When did the Frankish identity emerge?</td>\n      <td>None</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The Norman dynasty had a major political, cult...</td>\n      <td>Who was the duke in the battle of Hastings?</td>\n      <td>William the Conqueror</td>\n      <td>1022</td>\n      <td>1042</td>\n      <td>[William the Conqueror, William the Conqueror]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Validation set size: 11873\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fine tuning Bert for question answering in SQuAD 2.0**"
      ],
      "metadata": {
        "id": "MrHLJVNuAN1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for **GPU availability**. GPU is a very powerful resource for running similar tasks which use deep neural architectures like transformers"
      ],
      "metadata": {
        "id": "M424s6KLq7OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on GPU/Cuda' if torch.cuda.is_available() else 'Running on CPU')"
      ],
      "metadata": {
        "id": "Crbx7OBlBZ7K",
        "outputId": "ef4b7536-f530-4d99-8bc3-6aa8b9ac04ea",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:59.205272Z",
          "iopub.execute_input": "2022-03-02T16:17:59.206001Z",
          "iopub.status.idle": "2022-03-02T16:17:59.263311Z",
          "shell.execute_reply.started": "2022-03-02T16:17:59.205938Z",
          "shell.execute_reply": "2022-03-02T16:17:59.262269Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Running on GPU/Cuda\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two most common **metrics** to evaluate the question answering performance in SQuAD are the **Exact Match score** and the **f1 score**. The implementation of those scores is inspired by the squad_metrics.py of the Hugging Face library"
      ],
      "metadata": {
        "id": "XXmECZwRmpBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "    # Lowercasing and punctuation removal\n",
        "    normalized_text = \"\".join(ch.lower() for ch in text if ch not in set(string.punctuation))\n",
        "    # Article removal\n",
        "    article_regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    normalized_text = re.sub(article_regex, \" \", normalized_text)\n",
        "    # Whitespace removal\n",
        "    normalized_text = \" \".join(normalized_text.split())\n",
        "\n",
        "    return normalized_text\n",
        "\n",
        "def exact_match_score(pred_answer, gold_answer):\n",
        "    return int(normalize_text(pred_answer) == normalize_text(gold_answer))\n",
        "\n",
        "def f1_score(pred_answer, gold_answer):\n",
        "  pred_tokens = normalize_text(pred_answer).split()\n",
        "  gold_tokens = normalize_text(gold_answer).split()\n",
        "  \n",
        "  # if either the prediction or the ground truth is no-answer then f1 = 1 if they agree and 0 otherwise\n",
        "  if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n",
        "      return int(pred_tokens == gold_tokens)\n",
        "  \n",
        "  common = Counter(gold_tokens) & Counter(pred_tokens)\n",
        "  num_same = sum(common.values())\n",
        "  \n",
        "  # If there are no common tokens then f1 = 0\n",
        "  if num_same == 0:\n",
        "    return 0\n",
        "  \n",
        "  precision = 1.0 * num_same / len(pred_tokens)\n",
        "  recall = 1.0 * num_same / len(gold_tokens)\n",
        "  \n",
        "  return 2 * (precision * recall) / (precision + recall)"
      ],
      "metadata": {
        "id": "TdTd_I_6mIIE",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:59.265817Z",
          "iopub.execute_input": "2022-03-02T16:17:59.266596Z",
          "iopub.status.idle": "2022-03-02T16:17:59.281548Z",
          "shell.execute_reply.started": "2022-03-02T16:17:59.266505Z",
          "shell.execute_reply": "2022-03-02T16:17:59.280258Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useful function for  **perfomance visualization**. This function is used for plotting **learning curves** (loss vs epochs)"
      ],
      "metadata": {
        "id": "8tAf4u5bBnVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLearningCurves(x_axis, y_axis, x_label, y_label, curve_ids, legend_loc = 'lower right', x_best = None, y_best = None):\n",
        "  fig = plt.figure(figsize = (7, 7))\n",
        "  if x_best is not None and y_best is not None:\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.annotate('Best score ' + str(x_best), xy = (x_best, y_best), arrowprops = dict(facecolor = 'black', shrink = 0.05))\n",
        "  for y, id in zip(y_axis, curve_ids):\n",
        "    plt.plot(x_axis, y, label = id,  linewidth = 3)\n",
        "  plt.title('Learning Curves')\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  plt.legend(loc = legend_loc)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "y3RxbHudBmwH",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:59.283744Z",
          "iopub.execute_input": "2022-03-02T16:17:59.284483Z",
          "iopub.status.idle": "2022-03-02T16:17:59.295922Z",
          "shell.execute_reply.started": "2022-03-02T16:17:59.284433Z",
          "shell.execute_reply": "2022-03-02T16:17:59.294578Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Popular **learning rate scheldulers**. **Linear warmup** schelduler is the most used by Bert"
      ],
      "metadata": {
        "id": "gRdKg5-mo_wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheldulers = {\n",
        "  'Exponential': lambda optimizer, step: torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.1 ** (epoch / step)), # Initial lr* 0.1^(t/step)\n",
        "  'Power': lambda optimizer, step: torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 1 / (1 + epoch / step)), # Initial lr/ (1 + t/step)\n",
        "  'Piecewise': lambda optimizer, milestones:  torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = milestones, gamma = 0.1), # lr for 1 <= epoch < m1, lr*0.1 for m1 <= epoch < m2 ...\n",
        "  'Performance': lambda optimizer, patience, factor : torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience = patience, factor = factor),\n",
        "  'OneCycle': lambda optimizer, steps_per_epoch, epochs, max_lr : torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = max_lr, anneal_strategy = 'linear', steps_per_epoch = steps_per_epoch, epochs = epochs),\n",
        "  'LinearWarmup': get_linear_schedule_with_warmup\n",
        "}"
      ],
      "metadata": {
        "id": "X18hByvYj3dQ",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:59.298009Z",
          "iopub.execute_input": "2022-03-02T16:17:59.298428Z",
          "iopub.status.idle": "2022-03-02T16:17:59.310962Z",
          "shell.execute_reply.started": "2022-03-02T16:17:59.298326Z",
          "shell.execute_reply": "2022-03-02T16:17:59.309870Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some useful **building blocks** are specified in order to help with the development of the actual Bert model. At first, the initial SQuAD datasets must be **transformed** to a format that Bert \"understands\" (e.g token ids, segment ids, attention mask). For that reason a new **custom dataset** is created that **keeps the reference** to the initial dataset and stores all the SQuAD records of that initial dataset into some encoded Bert based records. The encoding is achieved using the encode for Bert method. This method performs the **tokenization** and the **truncation** to produce the **input tokens** and also creates the **segment ids** and the **attention mask** from the extracted tokens. Meanwhile, it **translates/maps** the above character based answer spans of the context to **token based spans** in order to indicate the start and the end positions to the Bert model. The information for every SQuAD record is stored in an encoding instance and this instance is used either to **create a record** in a format that is acceptable by Bert as mentioned above or to perform a functionality that also requires a mapping and is **related to the initial dataset** (e.g building an answer span from predictions for a specific record of the dataset). Finally, one problem is that the input lengths might differ and some padding must also be applied. In order to reduce **memory space** and **excecution time** (and better results) some external functions are specified to apply the **padding dynamically**. Dynamic padding adds some 0s to all the above encodings up to the **longest length** in the currently processed by the model batch."
      ],
      "metadata": {
        "id": "AWmWpJ1BrYpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset for SQuAD\n",
        "class BertSquadDataset(torch.utils.data.Dataset):\n",
        "  # A SQuAD record factory/generator \n",
        "  BertSquadRecord = namedtuple('BertSquadRecord', ['input_ids', 'token_type_ids', 'attention_mask', 'start_position', 'end_position', 'squad_id'])\n",
        "  \n",
        "  tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  def __init__(self, squad_df, max_length = None):\n",
        "    self.squad_encodings = []\n",
        "    self.max_length = max_length\n",
        "    self.squad_df = squad_df\n",
        "\n",
        "    for row in squad_df.itertuples():\n",
        "      self.add_item(row.context, row.question, row.answer_start_idx, row.answer_end_idx, row.Index)\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.squad_encodings)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return BertSquadDataset.BertSquadRecord(**self.squad_encodings[idx])\n",
        "\n",
        "  def add_item(self, context, question, answer_start_idx, answer_end_idx, squad_id = None):\n",
        "    encoding = BertSquadDataset.createBertSquadEncoding(context, question, answer_start_idx, answer_end_idx, self.max_length)\n",
        "    encoding.update({'squad_id': squad_id})\n",
        "    self.squad_encodings.append(encoding)\n",
        "  \n",
        "  # Constructs an answer for a specific record in the dataset given a span (it is mostly used to construct the predicted answer of Bert)\n",
        "  def buildBertAnswer(self, idx, start_position, end_position):\n",
        "    # Start position cannot be after the end position\n",
        "    if start_position > end_position:\n",
        "      return None\n",
        "    \n",
        "    # No answer\n",
        "    if start_position == 0 and end_position == 0:\n",
        "      return ''\n",
        "\n",
        "    # The encoding that is stored for the specific squad record\n",
        "    encoding = self.squad_encodings[idx]\n",
        "    input_ids = encoding.input_ids\n",
        "\n",
        "    # The first context token is located right after the first occurance of the SEP token\n",
        "    context_start_token_idx = input_ids.index(BertSquadDataset.tokenizer.sep_token_id) + 1\n",
        "    # The last context token is located right before the last SEP token\n",
        "    context_end_token_idx = len(input_ids) - 2\n",
        "\n",
        "    # If the start of the span is out of the context then there is no answer (it is not acceptable for an answer to start in a question or a padding area)\n",
        "    if start_position < context_start_token_idx or start_position > context_end_token_idx:\n",
        "      return None\n",
        "    \n",
        "    # If the end of the span is out of the context then it can be truncated to the end of the context (i.e whenever the answer contains some padding it can be removed)\n",
        "    end_position = min(end_position, context_end_token_idx)\n",
        "\n",
        "    # Encoding keeps the offset mapping\n",
        "    answer_start_idx = encoding.token_to_chars(start_position)[0]\n",
        "    answer_end_idx = encoding.token_to_chars(end_position)[1]\n",
        "\n",
        "    context = self.squad_df['context'][idx]\n",
        "    answer_in_context = context[answer_start_idx:answer_end_idx]\n",
        "\n",
        "    return answer_in_context\n",
        "  \n",
        "  @staticmethod\n",
        "  def encodeSquadForBert(context, question, answer_start_idx, answer_end_idx, max_length = None):\n",
        "    # Whenever max length is given then truncation is applied only to context/passage\n",
        "    truncation = 'only_second' if max_length else False\n",
        "\n",
        "    encoding = BertSquadDataset.tokenizer(question, context, max_length = max_length, truncation = truncation, return_offsets_mapping = True)\n",
        "    # Initialization of the start and end positions ((0, 0) indicates the CLS token which is used when an answer cannot be found)\n",
        "    encoding.update({'start_position': 0, 'end_position': 0})\n",
        "    # This mapping will be used instead of the char_to_token and token_to_char functions of the encoding for more flexibility\n",
        "    offset_mapping = encoding.pop('offset_mapping')\n",
        "\n",
        "    # If either the start or the end of the answer is missing then start and end positions cannot be found \n",
        "    if answer_start_idx < 0 or answer_end_idx < 0:\n",
        "      return encoding\n",
        "    \n",
        "    # The first context token is located right after the first occurance of the SEP token\n",
        "    context_start_token_idx = encoding['input_ids'].index(BertSquadDataset.tokenizer.sep_token_id) + 1\n",
        "    # The last context token is located right before the last SEP token\n",
        "    context_end_token_idx = len(encoding['input_ids']) - 2\n",
        "    \n",
        "    context_start_idx = offset_mapping[context_start_token_idx][0]\n",
        "    context_end_idx = offset_mapping[context_end_token_idx][1] - 1\n",
        "\n",
        "    # If the answer is out of the context bounds (e.g has been truncated) there is no reason to search for its start and end positions\n",
        "    if context_start_idx > answer_start_idx or context_end_idx < answer_end_idx:\n",
        "      return encoding\n",
        "    \n",
        "    # Start and end positions are calculated in such a way to cover the whole answer without losing information\n",
        "    # But sometimes a bad tokenization can add a little noise if some tokens include both some characters of the answer and some characters out of the answer\n",
        "\n",
        "    start_position = context_start_token_idx\n",
        "    while offset_mapping[start_position][1] - 1 < answer_start_idx:\n",
        "      start_position += 1\n",
        "    \n",
        "    end_position = context_end_token_idx\n",
        "    while offset_mapping[end_position][0] > answer_end_idx:\n",
        "      end_position -= 1\n",
        "    \n",
        "    encoding.update({'start_position': start_position, 'end_position': end_position})\n",
        "\n",
        "    return encoding\n",
        "  \n",
        "  @staticmethod\n",
        "  def createBertSquadEncoding(context, question, answer_start_idx, answer_end_idx, max_length = None):\n",
        "    encoding = BertSquadDataset.encodeSquadForBert(context, question, answer_start_idx, answer_end_idx, max_length)\n",
        "    return encoding\n",
        "\n",
        "def padSequence(batch, padding_value = 0): \n",
        "  max_len = max([len(x) for x in batch])\n",
        "  batch_padded = []\n",
        "  for x in batch:\n",
        "    x_padded = [padding_value] * max_len\n",
        "    x_padded[:len(x)] = x\n",
        "    batch_padded.append(x_padded)\n",
        "    \n",
        "  return batch_padded\n",
        "\n",
        "# Collate function that is going to be used by the Dataloader in order to add padding to each batch\n",
        "def padCollate(batch, padding_value = 0):\n",
        "  (batch_input_ids, batch_token_type_ids, batch_attention_masks, batch_start_positions, batch_end_positions, batch_ids) = zip(*batch)\n",
        "\n",
        "  batch_labels = {\n",
        "      'start_positions': torch.tensor(batch_start_positions, device = device),\n",
        "      'end_positions': torch.tensor(batch_end_positions, device = device)\n",
        "  } \n",
        "  \n",
        "  # Padding all the sequences to have equal lengths (the length is equal to the length of the longest sequence in the batch)\n",
        "  # Padding is applied to the segment ids and the attention masks as well\n",
        "  batch_padded_features = {'input_ids': padSequence(batch_input_ids), \n",
        "                           'token_type_ids': padSequence(batch_token_type_ids),\n",
        "                           'attention_mask': padSequence(batch_attention_masks)\n",
        "                          }\n",
        "  \n",
        "  return BatchEncoding(batch_padded_features, tensor_type = 'pt').to(device), batch_labels, batch_ids\n",
        "          "
      ],
      "metadata": {
        "id": "7q7LCPIaCCwK",
        "outputId": "4e76e602-b12a-456d-c605-31de0bb5509d",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:17:59.313421Z",
          "iopub.execute_input": "2022-03-02T16:17:59.313873Z",
          "iopub.status.idle": "2022-03-02T16:18:05.733442Z",
          "shell.execute_reply.started": "2022-03-02T16:17:59.313827Z",
          "shell.execute_reply": "2022-03-02T16:18:05.732461Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "b72a3d117e604378969f7215f57a305c",
            "02b77977ae1d4848af9a41d6c66f60d2",
            "2b0ee93b1c03443c93afd305ec9d6ed6",
            "6097aa7186df483591bfc7c5b8ed0f92"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b72a3d117e604378969f7215f57a305c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02b77977ae1d4848af9a41d6c66f60d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b0ee93b1c03443c93afd305ec9d6ed6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6097aa7186df483591bfc7c5b8ed0f92"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the actual class of the **Bert for SQuAD Question Answering**. This class is a wrapper of the **BertForQuestionAnswering** which is already implemented and provided by the Hugging Face library and has been extended with some extra functionalities in order to automate all the training and evaluation process as much as possible. Especially, at the evaluation stage the above metrics (Extact Match and f1 score) are incoorporated for **calculating the scores** for the every single record in the validation/dev dataset. In order the model to predict better answers there is a kind of a **mini exhaustive search** between the **top k** (k is predefined and it can be an extra hyperparameter) possible and fisible spans. Furthermore, there are two functions for **training**, both supporting **gradient clipping**, but the one with the more options (stats, early stopping etc...) it is going to be used below. Moreover, these functions support **learning rate schelduling** and they call in every epoch the **batch** training submethod to train all the batches. Finally, there is one method for making predictions for any given unseen input but using a naive method to extract them"
      ],
      "metadata": {
        "id": "KAdWWmE2CFMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSquad(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Instantiate Bert for QA\n",
        "        self.bert = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def forward(self, bertInputConfig, start_positions = None, end_positions = None):\n",
        "\n",
        "        out = self.bert(**bertInputConfig, start_positions = start_positions, end_positions = end_positions)\n",
        "            \n",
        "        return out\n",
        "    \n",
        "    def batchTrain(self, batch_loader, optimizer, schelduler = None, max_clip_norm = None):\n",
        "      total_loss = 0.0\n",
        "\n",
        "      for x_batch, y_batch, _ in tqdm(batch_loader, 'Batch Training'):\n",
        "        # Gradients are restored to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = self(x_batch, **y_batch)\n",
        "\n",
        "        loss = pred.loss\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Backpropagation starting from the loss calculated in this epoch\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        if max_clip_norm is not None:\n",
        "          nn.utils.clip_grad_norm_(self.parameters(), max_clip_norm)\n",
        "        # Model's weights update based on the gradients calculated during backprop\n",
        "        optimizer.step()\n",
        "\n",
        "        # Some scheldulers can make steps inside the batches such as OneCycle schelduler\n",
        "        if schelduler is not None:\n",
        "          schelduler.step()\n",
        "          #print(schelduler.state_dict())\n",
        "\n",
        "      return total_loss / len(batch_loader) # Average loss\n",
        "    \n",
        "    def batchEval(self, batch_loader, search_best_span_limit = 20):\n",
        "          total_loss = 0.0\n",
        "          total = 0.0\n",
        "          em_scores = 0.0\n",
        "          f1_scores = 0.0\n",
        "\n",
        "          with torch.no_grad():\n",
        "            for x_batch, y_batch, batch_ids in tqdm(batch_loader, 'Batch Evaluation'):\n",
        "              pred = self(x_batch, **y_batch)\n",
        "\n",
        "              loss = pred.loss\n",
        "              start_logits = pred.start_logits\n",
        "              end_logits = pred.end_logits\n",
        "                \n",
        "              total_loss += loss.item() \n",
        "\n",
        "              # Instead of using `pred_start_positions = torch.argmax(start_logits, dim = 1)` to find the best start that might be invalid, the range is extended to the top k\n",
        "              pred_start_indices = torch.topk(start_logits, search_best_span_limit, dim = 1).indices.cpu().detach().numpy()\n",
        "              # Instead of using `pred_end_positions = torch.argmax(end_logits, dim = 1)` to find the best end that might be invalid, the range is extended to the top k\n",
        "              pred_end_indices = torch.topk(end_logits, search_best_span_limit, dim = 1).indices.cpu().detach().numpy()\n",
        "\n",
        "              #pred_spans = torch.cat([pred_start_positions.unsqueeze(1), pred_end_positions.unsqueeze(1)], dim = 1).cpu().detach().numpy()\n",
        "\n",
        "              for i, (starts, ends) in enumerate(zip(pred_start_indices, pred_end_indices)):\n",
        "                id = batch_ids[i]\n",
        "                pred_answer = None\n",
        "                best_span_score = float('-inf')\n",
        "                # Searching for a fisible span with the best score\n",
        "                for start in starts: \n",
        "                  for end in ends:\n",
        "                    sum = start_logits[i][start] + end_logits[i][end]\n",
        "                    if sum.item() > best_span_score:\n",
        "                      span_text = batch_loader.dataset.buildBertAnswer(id, start, end)\n",
        "                      if span_text is not None: # If answer is valid\n",
        "                        pred_answer = span_text\n",
        "                        best_span_score = sum\n",
        "                \n",
        "                if pred_answer is None: # If no valid answer found at all\n",
        "                  pred_answer = '' \n",
        "\n",
        "                answer = batch_loader.dataset.squad_df['answer'][id]\n",
        "                if answer is not None:\n",
        "                  other_answers = batch_loader.dataset.squad_df['other_answers'][id] or []\n",
        "                  all_answers = [*other_answers, answer]\n",
        "                else:\n",
        "                  all_answers = ['']\n",
        "                # Calculation of the Exact Match score and f1 score between the predicted answer and all the gold/ground truth answers  \n",
        "                em_scores += max((exact_match_score(pred_answer, answer)) for answer in all_answers)\n",
        "                f1_scores += max((f1_score(pred_answer, answer)) for answer in all_answers)\n",
        "                total += 1\n",
        "              \n",
        "          return [total_loss / len(batch_loader), em_scores / total, f1_scores / total]\n",
        "        \n",
        "    def fineTuning(self, training_set, optimizer, lr_schelduler = None, max_clip_norm = None, epochs = 3, batch_size = 32):\n",
        "      # Switching to training mode\n",
        "      self.train()\n",
        "\n",
        "      # Training batches\n",
        "      batch_loader = torch.utils.data.DataLoader(training_set, batch_size = batch_size, shuffle = True, collate_fn = padCollate)\n",
        "      \n",
        "      # Creating the right schelduling function\n",
        "      if lr_schelduler is not None:\n",
        "        if lr_schelduler['name'] != 'Performance':\n",
        "          schelduler = lr_schelduler['schelduler']\n",
        "        else:\n",
        "          raise Exception('Performance schelduling cannot be applied')\n",
        "\n",
        "      for epoch in range(1, epochs + 1):\n",
        "        print(f'\\nEpoch: {epoch}')\n",
        "        if lr_schelduler is not None and not lr_schelduler['epoch_step']:  # For OneCycle schelduler for example is better to make steps inside the batches\n",
        "          loss_score = self.batchTrain(batch_loader, optimizer, schelduler, max_clip_norm)\n",
        "        else:\n",
        "          loss_score = self.batchTrain(batch_loader, optimizer, None, max_clip_norm)\n",
        "    \n",
        "        # Learning rate modification for the next epoch\n",
        "        if lr_schelduler is not None and lr_schelduler['epoch_step']:\n",
        "          schelduler.step()\n",
        "          #print(schelduler.state_dict())\n",
        "        \n",
        "        print(f'Loss = {loss_score:.5f}')\n",
        "\n",
        "    def fineTuningWithOptions(self, training_set, optimizer, validation_set = None, lr_schelduler = None, max_clip_norm = None, epochs = 3, batch_size = 32, stats = False, early_stopping_params = None):\n",
        "      if validation_set is not None and (stats != False or early_stopping_params is not None or (lr_schelduler is not None and lr_schelduler['name'] == 'Performance')): \n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        valid_em_scores = []\n",
        "        valid_f1_scores = []\n",
        "        best_score = float('inf')\n",
        "        best_iter = 1\n",
        "        counter = 0\n",
        "        epoch = 1\n",
        "\n",
        "        # Training batches\n",
        "        training_batch_loader = torch.utils.data.DataLoader(training_set, batch_size = batch_size, shuffle = True, collate_fn = padCollate)\n",
        "\n",
        "        # Validation batches\n",
        "        validation_batch_loader = torch.utils.data.DataLoader(validation_set, batch_size = batch_size, collate_fn = padCollate)\n",
        "\n",
        "        # Creating the right schelduling function\n",
        "        if lr_schelduler is not None:\n",
        "          schelduler = lr_schelduler['schelduler']\n",
        "        \n",
        "        for epoch in range(1, epochs + 1): \n",
        "          if stats: \n",
        "            print(f'\\nEpoch: {epoch}')\n",
        "          # Switching to training mode\n",
        "          self.train()\n",
        "          # Batch training and calculation of the average training batch scores (accuracy score, loss, f1 score)\n",
        "          if lr_schelduler is not None and not lr_schelduler['epoch_step']:  # For OneCycle schelduler for example is better to make steps inside the batches\n",
        "            train_loss = self.batchTrain(training_batch_loader, optimizer, schelduler, max_clip_norm)\n",
        "          else:\n",
        "            train_loss = self.batchTrain(training_batch_loader, optimizer, None, max_clip_norm)\n",
        "\n",
        "          train_losses.append(train_loss)\n",
        "\n",
        "          # Switching to evaluation mode\n",
        "          self.eval()\n",
        "          # Calculation of validation batch scores\n",
        "          valid_loss, valid_em_score, valid_f1_score =  self.batchEval(validation_batch_loader)\n",
        "\n",
        "          valid_losses.append(valid_loss)\n",
        "          valid_em_scores.append(valid_em_score)\n",
        "          valid_f1_scores.append(valid_f1_score)\n",
        "\n",
        "          if valid_loss < best_score:\n",
        "            best_score = valid_loss\n",
        "            best_iter = epoch\n",
        "            counter = 0\n",
        "          else: \n",
        "            counter += 1\n",
        "\n",
        "          # If validation set starts increasing by reaching a small patience then maybe the model starts to overfit. So model training has to stop as soon as possible\n",
        "          if early_stopping_params is not None and counter == early_stopping_params['patience']:\n",
        "            break\n",
        "          \n",
        "          # Learning rate modification for the next epoch\n",
        "          if lr_schelduler is not None:\n",
        "            if lr_schelduler['name'] == 'Performance': # Validation loss must be passed to the performance schelduler\n",
        "              schelduler.step(valid_loss)\n",
        "            elif lr_schelduler['epoch_step']:\n",
        "              schelduler.step()\n",
        "            #print(schelduler.state_dict())\n",
        "\n",
        "          if stats: \n",
        "            print(f'Training: Loss = {train_loss:.5f}')\n",
        "            print(f'Validation: Loss = {valid_loss:.5f}, Exact match = {valid_em_score:.5f}, F1 score = {valid_f1_score:.5f}')\n",
        "        \n",
        "        if stats:\n",
        "          # Learning curve plot\n",
        "          plotLearningCurves(list(range(1, epoch + 1)), [valid_losses, train_losses], 'Number of Iterations', 'Loss', ['validation', 'training'], 'upper right', best_iter, best_score)\n",
        "          \n",
        "          return [train_losses, valid_losses, valid_em_scores, valid_f1_scores]\n",
        "          \n",
        "      elif validation_set is None and (stats != False or early_stopping_params is not None or (lr_schelduler is not None and lr_schelduler['name'] == 'Performance')): \n",
        "        raise Exception('Validation set must not be None in order to calculate stats or to do early stopping or to do performance schelduling')\n",
        "      else: \n",
        "        self.fineTuning(training_set, optimizer, lr_schelduler, max_clip_norm, epochs, batch_size)\n",
        "    \n",
        "    def predict(self, X):\n",
        "      # Switching to evaluation mode\n",
        "      self.eval()\n",
        "      with torch.no_grad():\n",
        "          # Model computes the span of each answer\n",
        "          pred = self(X)\n",
        "          \n",
        "          start_logits = pred.start_logits\n",
        "          end_logits = pred.end_logits\n",
        "          \n",
        "          # A naive solution for extracting the answer\n",
        "          pred_start_positions = torch.argmax(start_logits, dim = 1)\n",
        "          pred_end_positions = torch.argmax(end_logits, dim = 1)\n",
        "\n",
        "          pred_spans = torch.cat([pred_start_positions.unsqueeze(1), pred_end_positions.unsqueeze(1)], dim = 1)\n",
        "\n",
        "          return pred_spans\n"
      ],
      "metadata": {
        "id": "L0XedV76CIF0",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:18:05.740516Z",
          "iopub.execute_input": "2022-03-02T16:18:05.742887Z",
          "iopub.status.idle": "2022-03-02T16:18:05.816045Z",
          "shell.execute_reply.started": "2022-03-02T16:18:05.742844Z",
          "shell.execute_reply": "2022-03-02T16:18:05.814801Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom made function for **fine tuning** using a **grid search**"
      ],
      "metadata": {
        "id": "PaMkijPShngc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def customGridSearch(param_grid, training_set, validation_set):\n",
        "  i = 1\n",
        "  for batch_size in param_grid['batch_sizes']:\n",
        "    for learning_rate in param_grid['learning_rates']:\n",
        "\n",
        "      model = BertForSquad().to(device)\n",
        "      \n",
        "      # AdamW is an improved version of Adam to better handle the weight decay factor (thats why it is prefered against Adam)\n",
        "      # Default values of AdamW are the same with the values used at the pretraining phase of Bert\n",
        "      optimizer = torch.optim.AdamW(model.parameters(), learning_rate['val'], weight_decay = 1e-2)\n",
        "\n",
        "      schelduler = None\n",
        "      # Creation of the schelduler with some default values (e.g steps, etc..)\n",
        "      if learning_rate['schelduler']:\n",
        "        total_steps = math.ceil(len(training_set) / batch_size) * param_grid['epochs']\n",
        "        if learning_rate['schelduler'] == 'Exponential':\n",
        "          schelduler = {'name':  'Exponential', 'schelduler': scheldulers['Exponential'](optimizer, 5), 'epoch_step': True}\n",
        "        if learning_rate['schelduler'] == 'Power':\n",
        "          schelduler = {'name':  'Power', 'schelduler': scheldulers['Power'](optimizer, 5), 'epoch_step': True}\n",
        "        if learning_rate['schelduler'] == 'Piecewise':\n",
        "          schelduler = {'name':  'Piecewise', 'schelduler': scheldulers['Piecewise'](optimizer, [0.2 * param_grid['epochs'], 0.5 * param_grid['epochs'], 0.8 * param_grid['epochs']]), 'epoch_step': True} \n",
        "        if learning_rate['schelduler'] == 'Performance':\n",
        "          schelduler = {'name':  'Performance', 'schelduler': scheldulers['Performance'](optimizer, 3, 0.5), 'epoch_step': True}\n",
        "        if learning_rate['schelduler'] == 'OneCycle':\n",
        "          schelduler = {'name':  'OneCycle', 'schelduler': scheldulers['OneCycle'](optimizer, total_steps / param_grid['epochs'], param_grid['epochs'], learning_rate['val'] * 100), 'epoch_step': False}\n",
        "        if learning_rate['schelduler'] == 'Linear': # Linear learning rate decay (thats why the warmup steps are 0) is the most popular schelduler and most used in many common tasks\n",
        "          schelduler = {'name':  'Linear', 'schelduler': scheldulers['LinearWarmup'](optimizer, num_warmup_steps = 0, num_training_steps = total_steps), 'epoch_step': False}\n",
        "        if learning_rate['schelduler'] == 'LinearWarmup': # Linear warmup 20% of the total steps \n",
        "          schelduler = {'name':  'LinearWarmup', 'schelduler': scheldulers['LinearWarmup'](optimizer, num_warmup_steps = 0.2 * total_steps, num_training_steps = total_steps), 'epoch_step': False} \n",
        "\n",
        "      curr_grid = f'Grid Search {i} Batch size: {batch_size}, Learning rate: {learning_rate[\"val\"]}, Schelduler: {learning_rate[\"schelduler\"] if schelduler is not None else None}'\n",
        "      display(Markdown('**' + curr_grid + '**'))\n",
        "      \n",
        "      i += 1\n",
        "      # Timekeeping the training process\n",
        "      timestamp_start = time.time()\n",
        "      model.fineTuningWithOptions(training_set, optimizer, validation_set, schelduler, param_grid['max_clip_norm'], param_grid['epochs'], batch_size, True, None)\n",
        "      timestamp_end = time.time()\n",
        "      print(f'\\nTotal time: {timestamp_end - timestamp_start:.2f} seconds')\n"
      ],
      "metadata": {
        "id": "z_y2m3ishn7e",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:18:05.818039Z",
          "iopub.execute_input": "2022-03-02T16:18:05.818399Z",
          "iopub.status.idle": "2022-03-02T16:18:05.839733Z",
          "shell.execute_reply.started": "2022-03-02T16:18:05.818352Z",
          "shell.execute_reply": "2022-03-02T16:18:05.836026Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model fine tuning and evaluation section**"
      ],
      "metadata": {
        "id": "kHEOqPmj77aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training** and **validation datasets** creation including all the encoded Bert inputs of the SQuAD records. Also a max length value is defined for **length truncation**. This value is specified properly in order not to lose much information bearing in mind the memory limits as well "
      ],
      "metadata": {
        "id": "5X0-ZCWB77_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_squad_length = 384\n",
        "bert_training_set = BertSquadDataset(training_set, max_squad_length)\n",
        "bert_validation_set = BertSquadDataset(validation_set, max_squad_length)"
      ],
      "metadata": {
        "id": "wJyunK6QoPds",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:18:05.841797Z",
          "iopub.execute_input": "2022-03-02T16:18:05.842649Z",
          "iopub.status.idle": "2022-03-02T16:20:13.082477Z",
          "shell.execute_reply.started": "2022-03-02T16:18:05.842599Z",
          "shell.execute_reply": "2022-03-02T16:20:13.081446Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation of the basic/common hyperparameter options for fine tuning**"
      ],
      "metadata": {
        "id": "fpK3JdB38-Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This grid contains only the best value but the search can be extended between many values\n",
        "param_grid = {\n",
        "  'batch_sizes': [8],\n",
        "  'learning_rates': [{'val': val, 'schelduler': 'Linear'} for val in [5e-5]],\n",
        "  'max_clip_norm': None,\n",
        "  'epochs': 2,\n",
        "}\n",
        "\n",
        "customGridSearch(param_grid, bert_training_set, bert_validation_set)"
      ],
      "metadata": {
        "id": "rr8viKgK2_ST",
        "outputId": "702ebec3-7402-429d-e510-8fbc02a18bab",
        "execution": {
          "iopub.status.busy": "2022-03-02T16:20:13.084111Z",
          "iopub.execute_input": "2022-03-02T16:20:13.084858Z",
          "iopub.status.idle": "2022-03-02T18:54:35.911243Z",
          "shell.execute_reply.started": "2022-03-02T16:20:13.084814Z",
          "shell.execute_reply": "2022-03-02T18:54:35.910049Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "a71ebe14325640cc8518810274334612"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a71ebe14325640cc8518810274334612"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "**Grid Search 1 Batch size: 8, Learning rate: 5e-05, Schelduler: Linear**"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nEpoch: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Batch Training: 100%|██████████| 16290/16290 [1:07:18<00:00,  4.03it/s]\nBatch Evaluation: 100%|██████████| 1485/1485 [09:34<00:00,  2.59it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training: Loss = 1.23262\nValidation: Loss = 1.05639, Exact match = 0.70547, F1 score = 0.74055\n\nEpoch: 2\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Batch Training: 100%|██████████| 16290/16290 [1:07:20<00:00,  4.03it/s]\nBatch Evaluation: 100%|██████████| 1485/1485 [09:43<00:00,  2.54it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training: Loss = 0.64860\nValidation: Loss = 1.08197, Exact match = 0.73023, F1 score = 0.76417\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 504x504 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "name": "stdout",
          "text": "\nTotal time: 9238.02 seconds\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}